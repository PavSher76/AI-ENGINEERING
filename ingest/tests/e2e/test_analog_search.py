#!/usr/bin/env python3
"""
E2E —Ç–µ—Å—Ç—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
"""

import asyncio
import pytest
import json
import os
from typing import Dict, List, Any
from pathlib import Path

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
import sys
sys.path.append(str(Path(__file__).parent.parent.parent))

from rag.service.hybrid_search import HybridSearchService
from pipeline.vectorizer import DocumentVectorizer
from pipeline.parser import DocumentParser


class TestAnalogSearch:
    """–¢–µ—Å—Ç—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è"""
    
    @pytest.fixture
    async def search_service(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ –ø–æ–∏—Å–∫–∞"""
        service = HybridSearchService()
        return service
    
    @pytest.fixture
    async def vectorizer(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞"""
        vectorizer = DocumentVectorizer()
        await vectorizer.ensure_collections_exist()
        return vectorizer
    
    @pytest.fixture
    async def parser(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞"""
        return DocumentParser()
    
    @pytest.fixture
    def sample_equipment_data(self):
        """–¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è"""
        return [
            {
                "chunk_id": "pump_001",
                "content": "–¶–µ–Ω—Ç—Ä–æ–±–µ–∂–Ω—ã–π –Ω–∞—Å–æ—Å –¥–ª—è –ø–µ—Ä–µ–∫–∞—á–∫–∏ –∞–º–º–∏–∞–∫–∞. –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å 1000 –º3/—á, –Ω–∞–ø–æ—Ä 50 –º. –ú–∞—Ç–µ—Ä–∏–∞–ª –∫–æ—Ä–ø—É—Å–∞ - –Ω–µ—Ä–∂–∞–≤–µ—é—â–∞—è —Å—Ç–∞–ª—å 316L.",
                "project_id": "EC-Karat-2021",
                "object_id": "NH3-ATR-3500tpd",
                "discipline": "process",
                "doc_no": "AI-ENG-PID-001",
                "rev": "A",
                "chunk_type": "text",
                "tags": ["pump", "centrifugal", "ammonia", "stainless_steel"],
                "numeric": {
                    "flow_rate": {"value": 1000, "unit": "m3/h"},
                    "head": {"value": 50, "unit": "m"},
                    "material": "316L"
                }
            },
            {
                "chunk_id": "heat_exchanger_001",
                "content": "–ö–æ–∂—É—Ö–æ—Ç—Ä—É–±–Ω—ã–π —Ç–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫ TEMA E. –¢–µ–ø–ª–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ 5000 –∫–í—Ç. –†–∞–±–æ—á–µ–µ –¥–∞–≤–ª–µ–Ω–∏–µ 25 –±–∞—Ä, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ 200¬∞C.",
                "project_id": "EC-Karat-2021",
                "object_id": "NH3-ATR-3500tpd",
                "discipline": "process",
                "doc_no": "AI-ENG-SPEC-100",
                "rev": "A",
                "chunk_type": "text",
                "tags": ["heat_exchanger", "shell_tube", "TEMA"],
                "numeric": {
                    "heat_duty": {"value": 5000, "unit": "kW"},
                    "pressure": {"value": 25, "unit": "bar"},
                    "temperature": {"value": 200, "unit": "¬∞C"}
                }
            },
            {
                "chunk_id": "compressor_001",
                "content": "–¶–µ–Ω—Ç—Ä–æ–±–µ–∂–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –¥–ª—è —Å–∂–∞—Ç–∏—è —Å–∏–Ω—Ç–µ–∑-–≥–∞–∑–∞. –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å 50000 –º3/—á, —Å—Ç–µ–ø–µ–Ω—å —Å–∂–∞—Ç–∏—è 3.5.",
                "project_id": "EC-Karat-2021",
                "object_id": "NH3-ATR-3500tpd",
                "discipline": "process",
                "doc_no": "AI-ENG-SPEC-200",
                "rev": "A",
                "chunk_type": "text",
                "tags": ["compressor", "centrifugal", "synthesis_gas"],
                "numeric": {
                    "flow_rate": {"value": 50000, "unit": "m3/h"},
                    "compression_ratio": {"value": 3.5, "unit": ""}
                }
            },
            {
                "chunk_id": "valve_001",
                "content": "–®–∞—Ä–æ–≤–æ–π –∫—Ä–∞–Ω DN 200, PN 40. –ú–∞—Ç–µ—Ä–∏–∞–ª –∫–æ—Ä–ø—É—Å–∞ - —É–≥–ª–µ—Ä–æ–¥–∏—Å—Ç–∞—è —Å—Ç–∞–ª—å, —É–ø–ª–æ—Ç–Ω–µ–Ω–∏—è - PTFE.",
                "project_id": "EC-Karat-2021",
                "object_id": "NH3-ATR-3500tpd",
                "discipline": "piping",
                "doc_no": "AI-ENG-PID-002",
                "rev": "A",
                "chunk_type": "text",
                "tags": ["valve", "ball_valve", "carbon_steel"],
                "numeric": {
                    "diameter": {"value": 200, "unit": "mm"},
                    "pressure": {"value": 40, "unit": "bar"}
                }
            }
        ]
    
    async def test_centrifugal_pump_search(self, search_service, vectorizer, sample_equipment_data):
        """–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ —Ü–µ–Ω—Ç—Ä–æ–±–µ–∂–Ω—ã—Ö –Ω–∞—Å–æ—Å–æ–≤"""
        # –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        await vectorizer.vectorize_chunks(sample_equipment_data, "ae_text_m3")
        
        # –ü–æ–∏—Å–∫ —Ü–µ–Ω—Ç—Ä–æ–±–µ–∂–Ω—ã—Ö –Ω–∞—Å–æ—Å–æ–≤
        results = await search_service.search_analogs(
            equipment_description="—Ü–µ–Ω—Ç—Ä–æ–±–µ–∂–Ω—ã–π –Ω–∞—Å–æ—Å",
            equipment_type="pump",
            parameters={"flow_rate": 1000, "head": 50},
            limit=5
        )
        
        assert len(results) > 0, "–î–æ–ª–∂–µ–Ω –Ω–∞–π—Ç–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –Ω–∞—Å–æ—Å"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–π–¥–µ–Ω –Ω–∞—Å–æ—Å
        pump_found = False
        for result in results:
            content = result["content"].lower()
            if "–Ω–∞—Å–æ—Å" in content or "pump" in content:
                pump_found = True
                break
        
        assert pump_found, "–î–æ–ª–∂–µ–Ω –Ω–∞–π—Ç–∏ –Ω–∞—Å–æ—Å –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
        top_result = results[0]
        assert top_result["relevance_score"] > 0.1, "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤—ã—à–µ 0.1"
    
    async def test_heat_exchanger_search(self, search_service, vectorizer, sample_equipment_data):
        """–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ —Ç–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫–æ–≤"""
        # –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        await vectorizer.vectorize_chunks(sample_equipment_data, "ae_text_m3")
        
        # –ü–æ–∏—Å–∫ —Ç–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫–æ–≤
        results = await search_service.search_analogs(
            equipment_description="—Ç–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫ –∫–æ–∂—É—Ö–æ—Ç—Ä—É–±–Ω—ã–π",
            equipment_type="heat_exchanger",
            parameters={"heat_duty": 5000, "pressure": 25},
            limit=5
        )
        
        assert len(results) > 0, "–î–æ–ª–∂–µ–Ω –Ω–∞–π—Ç–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ç–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–π–¥–µ–Ω —Ç–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫
        heat_exchanger_found = False
        for result in results:
            content = result["content"].lower()
            if "—Ç–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫" in content or "heat exchanger" in content:
                heat_exchanger_found = True
                break
        
        assert heat_exchanger_found, "–î–æ–ª–∂–µ–Ω –Ω–∞–π—Ç–∏ —Ç–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö"
    
    async def test_compressor_search(self, search_service, vectorizer, sample_equipment_data):
        """–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä–æ–≤"""
        # –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        await vectorizer.vectorize_chunks(sample_equipment_data, "ae_text_m3")
        
        # –ü–æ–∏—Å–∫ –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä–æ–≤
        results = await search_service.search_analogs(
            equipment_description="—Ü–µ–Ω—Ç—Ä–æ–±–µ–∂–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä",
            equipment_type="compressor",
            parameters={"flow_rate": 50000, "compression_ratio": 3.5},
            limit=5
        )
        
        assert len(results) > 0, "–î–æ–ª–∂–µ–Ω –Ω–∞–π—Ç–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–π–¥–µ–Ω –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä
        compressor_found = False
        for result in results:
            content = result["content"].lower()
            if "–∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä" in content or "compressor" in content:
                compressor_found = True
                break
        
        assert compressor_found, "–î–æ–ª–∂–µ–Ω –Ω–∞–π—Ç–∏ –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö"
    
    async def test_valve_search(self, search_service, vectorizer, sample_equipment_data):
        """–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ –∞—Ä–º–∞—Ç—É—Ä—ã"""
        # –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        await vectorizer.vectorize_chunks(sample_equipment_data, "ae_text_m3")
        
        # –ü–æ–∏—Å–∫ –∞—Ä–º–∞—Ç—É—Ä—ã
        results = await search_service.search_analogs(
            equipment_description="—à–∞—Ä–æ–≤–æ–π –∫—Ä–∞–Ω",
            equipment_type="valve",
            parameters={"diameter": 200, "pressure": 40},
            limit=5
        )
        
        assert len(results) > 0, "–î–æ–ª–∂–µ–Ω –Ω–∞–π—Ç–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∫—Ä–∞–Ω"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–π–¥–µ–Ω –∫—Ä–∞–Ω
        valve_found = False
        for result in results:
            content = result["content"].lower()
            if "–∫—Ä–∞–Ω" in content or "valve" in content:
                valve_found = True
                break
        
        assert valve_found, "–î–æ–ª–∂–µ–Ω –Ω–∞–π—Ç–∏ –∫—Ä–∞–Ω –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö"
    
    async def test_hybrid_search_weights(self, search_service, vectorizer, sample_equipment_data):
        """–¢–µ—Å—Ç –≤–µ—Å–æ–≤ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
        # –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        await vectorizer.vectorize_chunks(sample_equipment_data, "ae_text_m3")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫
        results = await search_service.hybrid_search(
            query="–Ω–∞—Å–æ—Å –∞–º–º–∏–∞–∫",
            limit=5
        )
        
        assert len(results) > 0, "–î–æ–ª–∂–µ–Ω –Ω–∞–π—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        for result in results:
            assert "combined_score" in result, "–î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å combined_score"
            assert "search_types" in result, "–î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å search_types"
            assert "content" in result, "–î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å content"
            assert "metadata" in result, "–î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å metadata"
    
    async def test_search_with_filters(self, search_service, vectorizer, sample_equipment_data):
        """–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏"""
        # –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        await vectorizer.vectorize_chunks(sample_equipment_data, "ae_text_m3")
        
        # –ü–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–µ
        results = await search_service.hybrid_search(
            query="–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ",
            filters={"discipline": "process"},
            limit=5
        )
        
        assert len(results) > 0, "–î–æ–ª–∂–µ–Ω –Ω–∞–π—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ñ–∏–ª—å—Ç—Ä—É
        for result in results:
            discipline = result["metadata"].get("discipline")
            assert discipline == "process", f"–î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å 'process', –ø–æ–ª—É—á–µ–Ω–∞: {discipline}"
    
    async def test_search_relevance_scoring(self, search_service, vectorizer, sample_equipment_data):
        """–¢–µ—Å—Ç —Å–∫–æ—Ä–∏–Ω–≥–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏"""
        # –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        await vectorizer.vectorize_chunks(sample_equipment_data, "ae_text_m3")
        
        # –ü–æ–∏—Å–∫ —Å —Ä–∞–∑–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
        queries = [
            "—Ü–µ–Ω—Ç—Ä–æ–±–µ–∂–Ω—ã–π –Ω–∞—Å–æ—Å –∞–º–º–∏–∞–∫",
            "–Ω–∞—Å–æ—Å",
            "–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ",
            "–Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å xyz"
        ]
        
        for query in queries:
            results = await search_service.hybrid_search(
                query=query,
                limit=3
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            if len(results) > 1:
                for i in range(len(results) - 1):
                    assert results[i]["combined_score"] >= results[i + 1]["combined_score"], \
                        "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏"
    
    async def test_empty_search_results(self, search_service):
        """–¢–µ—Å—Ç –ø—É—Å—Ç—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞"""
        # –ü–æ–∏—Å–∫ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
        results = await search_service.search_analogs(
            equipment_description="–Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ xyz123",
            limit=5
        )
        
        # –ú–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –∏–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –Ω–∏–∑–∫–æ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å—é
        if len(results) > 0:
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –Ω–∏–∑–∫—É—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
            for result in results:
                assert result["relevance_score"] < 0.5, "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –Ω–∏–∑–∫–æ–π –¥–ª—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è"


# –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
async def run_tests():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    test_instance = TestAnalogSearch()
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Å—Ç—É—Ä—ã
    search_service = await test_instance.search_service()
    vectorizer = await test_instance.vectorizer()
    parser = await test_instance.parser()
    sample_data = test_instance.sample_equipment_data()
    
    print("–ó–∞–ø—É—Å–∫ E2E —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤...")
    
    try:
        # –¢–µ—Å—Ç 1: –ü–æ–∏—Å–∫ —Ü–µ–Ω—Ç—Ä–æ–±–µ–∂–Ω—ã—Ö –Ω–∞—Å–æ—Å–æ–≤
        print("–¢–µ—Å—Ç 1: –ü–æ–∏—Å–∫ —Ü–µ–Ω—Ç—Ä–æ–±–µ–∂–Ω—ã—Ö –Ω–∞—Å–æ—Å–æ–≤")
        await test_instance.test_centrifugal_pump_search(search_service, vectorizer, sample_data)
        print("‚úì –ü—Ä–æ–π–¥–µ–Ω")
        
        # –¢–µ—Å—Ç 2: –ü–æ–∏—Å–∫ —Ç–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫–æ–≤
        print("–¢–µ—Å—Ç 2: –ü–æ–∏—Å–∫ —Ç–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫–æ–≤")
        await test_instance.test_heat_exchanger_search(search_service, vectorizer, sample_data)
        print("‚úì –ü—Ä–æ–π–¥–µ–Ω")
        
        # –¢–µ—Å—Ç 3: –ü–æ–∏—Å–∫ –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä–æ–≤
        print("–¢–µ—Å—Ç 3: –ü–æ–∏—Å–∫ –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä–æ–≤")
        await test_instance.test_compressor_search(search_service, vectorizer, sample_data)
        print("‚úì –ü—Ä–æ–π–¥–µ–Ω")
        
        # –¢–µ—Å—Ç 4: –ü–æ–∏—Å–∫ –∞—Ä–º–∞—Ç—É—Ä—ã
        print("–¢–µ—Å—Ç 4: –ü–æ–∏—Å–∫ –∞—Ä–º–∞—Ç—É—Ä—ã")
        await test_instance.test_valve_search(search_service, vectorizer, sample_data)
        print("‚úì –ü—Ä–æ–π–¥–µ–Ω")
        
        # –¢–µ—Å—Ç 5: –í–µ—Å–∞ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
        print("–¢–µ—Å—Ç 5: –í–µ—Å–∞ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞")
        await test_instance.test_hybrid_search_weights(search_service, vectorizer, sample_data)
        print("‚úì –ü—Ä–æ–π–¥–µ–Ω")
        
        # –¢–µ—Å—Ç 6: –ü–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
        print("–¢–µ—Å—Ç 6: –ü–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏")
        await test_instance.test_search_with_filters(search_service, vectorizer, sample_data)
        print("‚úì –ü—Ä–æ–π–¥–µ–Ω")
        
        # –¢–µ—Å—Ç 7: –°–∫–æ—Ä–∏–Ω–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        print("–¢–µ—Å—Ç 7: –°–∫–æ—Ä–∏–Ω–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏")
        await test_instance.test_search_relevance_scoring(search_service, vectorizer, sample_data)
        print("‚úì –ü—Ä–æ–π–¥–µ–Ω")
        
        # –¢–µ—Å—Ç 8: –ü—É—Å—Ç—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print("–¢–µ—Å—Ç 8: –ü—É—Å—Ç—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
        await test_instance.test_empty_search_results(search_service)
        print("‚úì –ü—Ä–æ–π–¥–µ–Ω")
        
        print("\nüéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        
    except Exception as e:
        print(f"\n‚ùå –¢–µ—Å—Ç –ø—Ä–æ–≤–∞–ª–µ–Ω: {str(e)}")
        raise


if __name__ == "__main__":
    asyncio.run(run_tests())
